data<- data.frame(Column1 = c('P1', 'P1', 'P2', 'P3', 'P1', 'P1', 'P3', 'P4', 'P2', 'P4'), Column2 = c(5, 5, 3, 5, 2, 3, 4, 7, 10, 14))
View(data)
distinct(data,Column1)
library(dplyr)
distinct(data,Column1)
dat<-distinct(data,Column1)
View(dat)
data<- data.frame(Column1 = c('P1', NA, 'P2', 'P3', 'P1', 'P1', 'P3', 'P4', 'P2', 'P4'), Column2 = c(5, 5, 3, 5, 2, 3, 4, 7, 10, 14))
dat<-distinct(data,Column1)
View(dat)
data2<-mutate(data,Column1=tolower(Column1))
View(data2)
View(data)
id <- c(1,1,1,1,2,2,3,3,4,4,4)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,30,22,24,11,11,12)
mydata <- data.frame(id, day, value)
View(mydata)
View(mydata)
mm <-mydata %>%
group_by(id, day) %>%
filter(row_number(value) == 1)
library(dplyr)
mm <-mydata %>%
group_by(id, day) %>%
filter(row_number(value) == 1)
id <- c(1,1,1,1,2,2,3,3,4,4,4)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,30,22,24,11,11,12)
mydata <- data.frame(id, day, value)
mm <-mydata %>%
group_by(id, day) %>%
filter(row_number(value) == 1)
View(mm)
View(mm)
mm1 <-mydata %>%
group_by(id, day) %>%
arrange(value) %>%
filter(row_number(value) == 1)
View(mm1)
View(mm1)
mm1 <-mydata %>%
group_by(id, day) %>%
arrange(value)
id <- c(1,1,1,1,2,2,3,3,4,4,4)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,30,22,24,11,11,12)
mydata <- data.frame(id, day, value)
mm1 <-mydata %>%
group_by(id, day) %>%
arrange(value)
mm1 <-mydata %>%
group_by=c(id, day) %>%
arrange(value)
mm1 <-mydata %>%
group_by(id, day) %>%
arrange(value)
mm1 <-mydata %>%
group_by(id, day) %>%
arrange(value) %>%
filter(row_number(value) == 1)
mm1 <-mydata %>%
group_by(id, day) %>%
arrange(value) %>%
filter(row_number(value) == 1) %>%
ungroup() %>%
arrange(id,day)
id <- c(1,1,1,1,2,2,3,3,4,4,4)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,"111wo",22,24,11,11,12)
mydata <- data.frame(id, day, value)
as.numeric(mydata$value)
id <- c(1,1,1,1,2,2,3,3,4,4,0)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,"111wo",22,24,11,11,12)
mydata <- data.frame(id, day, value)
mydata<-mydata %>%
mutate(id=tolower(gsub(" ","",id)))
str(mydata)
id <- c(1,1,1,1,2,2,3,3,4,4,0)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,"111wo",22,24,11,11,12)
mydata <- data.frame(id, day, value)
str(mydata)
id <- c(1,1,1,1,2,2,3,3,4,4,NA)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,"111wo",22,24,11,11,12)
mydata <- data.frame(id, day, value)
str(mydata)
mydata<-mydata %>%
mutate(id=tolower(gsub(" ","",id)))
str(mydata)
id <- c(1,1,1,1,2,2,3,3,4,4,NA)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,"111wo",22,24,11,11,12)
mydata <- data.frame(id, day, value)
A <- data.frame(id = c(1,1,4,4,4),
obs1 = c(100, 90,80, 80, 100),id2 = c(1,2,4,4,5))
B <- data.frame(id = c(4,4,4,4,4),
obs1 = c(100, 90,80, 80, 100),id2 = c(1,2,4,4,5))
df <- list("F"=A, "E"=B)
group <- function(x){
x <-x %>%
filter(id==4)
}
myy <-lapply(df,group)
list2env(myy,envir=.GlobalEnv)
shiny::runApp('Documents/GitHub/Coursera_Data_Science_Certificate/9_Data Products/MyAPP')
runApp('Documents/GitHub/Coursera_Data_Science_Certificate/9_Data Products/sliderAPP')
runApp('Documents/GitHub/Coursera_Data_Science_Certificate/9_Data Products/PlotAPP')
shiny::runApp('Documents/GitHub/Coursera_Data_Science_Certificate/10_Data Science Capstone/shiny')
runApp('Documents/GitHub/Coursera_Data_Science_Certificate/10_Data Science Capstone/shiny')
runApp('Documents/GitHub/Coursera_Data_Science_Certificate/10_Data Science Capstone/shiny')
View(final)
x <- final %>%
filter(count!=1)
x <- final %>%
filter(count!=1) %>%
filter(count!=10000)
save(final, file = "final.Rdata")
runApp('Documents/GitHub/Coursera_Data_Science_Certificate/10_Data Science Capstone/shiny')
# Prepare the data for the quiz.
# load packages ----
library(corpus) # corpus is an R text processing package with full suppport for international text (Unicode)
library(dplyr)
library(ggplot2)
library(tm) # package used to remove numbers and strip whitespace from a text document
library(stringi) # the function checks whether all bytes in a string are in the ascii set 1,2,3,4...,127
# Set working directory
setwd("~/Documents/GitHub/Coursera_Data_Science_Certificate/10_Data Science Capstone/shiny")
# 1. Download and Read the data from web (Date: Dec 28, 2022) ----
url <- "https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip"
download.file(url, "final_dataset.zip")
unzip("final_dataset.zip")
# 2. Combine and subset the data ----
twitter <- readLines("final/en_US/en_US.twitter.txt", encoding="UTF-8", skipNul=TRUE)
blogs <- readLines("final/en_US/en_US.blogs.txt", encoding="UTF-8", skipNul=TRUE)
news <- readLines("final/en_US/en_US.news.txt", encoding="UTF-8", skipNul=TRUE)
data_combine <- c(twitter, blogs, news)
# check the encoding of of data_combine
# library(readr)
# guess_encoding(data_combine, n_max = 1000)
# data_sample <- data_combine
data_sample <- sample(data_combine, size=100000, replace=FALSE)
# 3. Clean the dataset ----
# remove special characters
data_sample_temp1 <- iconv(data_sample, "UTF-8","ASCII",sub="")
# Profanity filtering - task 1, remove bad words.
download.file("http://www.cs.cmu.edu/~biglou/resources/bad-words.txt", destfile = "bad_words.txt")
badword <- readLines("bad_words.txt", encoding="UTF-8")
data_sample_clean <- removeWords(data_sample_temp1, c(badword))
# 4. Get unigram, bigram, trigram ----
unigram <- term_stats(data_sample_clean, text_filter(drop=stopwords_en, drop_symbol = TRUE, drop_punct = TRUE, drop_number = TRUE), ngrams=1,type=T) %>% # remove punctuation and english stop words (is, this, and....),remove number, remove space, lowercase
mutate(term="") %>%
rename(NextWord=type1) %>%
select(-support)
bigram <- term_stats(data_sample_clean, text_filter(drop=stopwords_en, drop_symbol = TRUE, drop_punct = TRUE, drop_number = TRUE), ngrams=2,type=T) %>%
select(-term,-support) %>%
rename(term=type1) %>%
rename(NextWord=type2) %>%
mutate(count=count*10000)
trigram <- term_stats(data_sample_clean, text_filter(drop=stopwords_en, drop_symbol = TRUE, drop_punct = TRUE, drop_number = TRUE), ngrams=3,type=T) %>%
select(-term,-support) %>%
mutate(term = paste(type1,type2)) %>%
select(-type1,-type2) %>%
relocate(term) %>%
rename(NextWord=type3) %>%
mutate(count=count*100000)
final <- rbind(unigram,bigram,trigram)
final <- final %>%
filter(count!=1) %>%
filter(count!=10000)
save(final, file = "final.Rdata")
View(unigram)
runApp()
runApp('~/Desktop/dataScienceCaptoneProject-gh-pages/guessing_next_word')
runApp()
runApp()
library(png)
runApp()
runApp()
runApp('~/Documents/GitHub/Coursera_Data_Science_Certificate/9_Data Products/Code/PlotAPP')
runApp('~/Documents/GitHub/Coursera_Data_Science_Certificate/9_Data Products/Code/sliderAPP')
