View(pressure)
library(readr)
train <- read_csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-training.csv")
test <- read_csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-testing.csv")
training_data <- rbind(train,test)
View(test)
View(train)
train <- read_csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-training.csv")
test <- read_csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-testing.csv
train <- read_csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-training.csv")
library(readr)
train <- read_csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-training.csv")
test <- read_csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-testing.csv")
comparedf(test,train)
library(arsenal)
install.packages("arsenal")
library(arsenal)
comparedf(test,train)
summary(comparedf(test,train))
summary(comparedf(test,train))
library(readr)
train <- read_csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-training.csv")
test <- read_csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-testing.csv")
install.packages("arsenal")
library(arsenal)
summary(comparedf(test,train))
install.packages("arsenal")
summary(comparedf(test,train))
train$group <-1
test$group <-0
summary(comparedf(test,train,))
x <- rbind(test,train)
View(summary(comparedf(test,train)))
View(summary(comparedf(test, train))[["diffs.byvar.table"]])
View(summary(comparedf(test, train))[["vars.ns.table"]])
View(test)
test <- test %>%
mutate(problem_id=NA)
test <- test %>%
mutate(problem_id=NA) %>%
rename(problem_id=classe)
library(dplyr)
test <- test %>%
mutate(problem_id=NA) %>%
rename(problem_id=classe)
test <- test %>%
mutate(problem_id=NA) %>%
rename(classe=problem_id)
View(test)
training_data <- rbind(test,train)
x <- nearZeroVar(training_data)
x <- nearZeroVar(training_data)
# drop the variable with no or minimum variation
library(caret)
# drop the variable with no or minimum variation
install.packages(("caret"))
install.packages(("caret"))
library(caret)
x <- nearZeroVar(training_data)
y <- training_data[,x]
View(y)
xx <-x[-44]
y <- training_data[,xx]
training_data <- training_data[,-xx]
naprops <- colSums(is.na(training_data))/nrow(training_data)
mostlyNAs <- names(naprops[naprops > 0.75])
mostlyNACols <- which(naprops > 0.75)
training_data <- training_data[,-mostlyNACols]
library(readr)
train <- read_csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-training.csv", na.strings=c("NA","","#DIV/0!"))
train <- read.csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-training.csv", na.strings=c("NA","","#DIV/0!"))
test <- read.csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-testing.csv", na.strings=c("NA","","#DIV/0!"))
train$group <-1
test$group <-0
install.packages("arsenal")
install.packages("arsenal")
library(arsenal)
View(summary(comparedf(test,train)))
library(dplyr)
test <- test %>%
mutate(problem_id=NA) %>%
rename(classe=problem_id)
training_data <- rbind(test,train)
# drop the variable with no or minimum variation
install.packages(("caret"))
install.packages(("caret"))
library(caret)
x <- nearZeroVar(training_data)
y <- training_data[,x]
xx <-x[-44]
y <- training_data[,xx]
training_data <- training_data[,-xx]
# Remove the variables that are mde up of mostly NAs
naprops <- colSums(is.na(training_data))/nrow(training_data)
mostlyNAs <- names(naprops[naprops > 0.75])
mostlyNACols <- which(naprops > 0.75)
training_data <- training_data[,-mostlyNACols]
train <- read.csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-training.csv", na.strings=c("NA","","#DIV/0!"))
test <- read.csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-testing.csv", na.strings=c("NA","","#DIV/0!"))
train$group <-1
test$group <-0
library(arsenal)
View(summary(comparedf(test,train)))
View(summary(comparedf(test, train))[["comparison.summary.table"]])
View(summary(comparedf(test, train))[["comparison.summary.table"]])
View(summary(comparedf(test, train))[["vars.ns.table"]])
library(dplyr)
test <- test %>%
mutate(problem_id=NA) %>%
rename(classe=problem_id)
training_data <- rbind(test,train)
library(caret)
x <- nearZeroVar(training_data)
y <- training_data[,x]
View(y)
xx <-x[-37]
y <- training_data[,xx]
training_data <- training_data[,-xx]
# Remove the variables that are mde up of mostly NAs
naprops <- colSums(is.na(training_data))/nrow(training_data)
mostlyNAs <- names(naprops[naprops > 0.75])
mostlyNACols <- which(naprops > 0.75)
training_data <- training_data[,-mostlyNACols]
View(training_data)
traindata <- training_data[,-5]
View(traindata)
View(test)
View(train)
library(readr)
train <- read.csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-training.csv", na.strings=c("NA","","#DIV/0!"))
test <- read.csv("~/Documents/GitHub/Coursera_Data_Science_Certificate/8_Practical Machine Learning/pml-testing.csv", na.strings=c("NA","","#DIV/0!"))
train$group <-1
test$group <-0
library(arsenal)
View(summary(comparedf(test,train)))
library(dplyr)
test <- test %>%
mutate(problem_id=NA) %>%
rename(classe=problem_id)
training_data <- rbind(test,train)
# drop the variable with no or minimum variation
library(caret)
x <- nearZeroVar(training_data)
y <- training_data[,x]
xx <-x[-37]
y <- training_data[,xx]
training_data <- training_data[,-xx]
# Remove the variables that are mde up of mostly NAs
naprops <- colSums(is.na(training_data))/nrow(training_data)
mostlyNAs <- names(naprops[naprops > 0.50])
mostlyNACols <- which(naprops > 0.50)
training_data <- training_data[,-mostlyNACols]
View(training_data)
traindata <- training_data[,-5]
traindata <- training_data[,-c(1,5)]
View(training_data)
traindata <- training_data[,c(-1,-5)]
View(traindata)
View(traindata)
names(wich(sapply(traindata,anyNA)))
names(which(sapply(traindata,anyNA)))
z <-names(which(sapply(traindata,anyNA)))
summary(comparedf(test, train))[["comparison.summary.table"]]
str(traindata)
trainclean <- traindata[group==1,]
testclean <- traindata[gropu==0,]
trainclean <- traindata[traindata$group==1,]
testclean <- traindata[traindata$group==0,]
View(trainclean)
library(caret)
library(kernlab);data(spam)
View(spam)
# Use createDataPartition to separate training set and test set.
inTrain <- createDataPartition(y=trainclean$classe,p=0.6, list=FALSE) # split the data set in to 75% training
training <- trainclean[inTrain,]
testing <- trainclean[-inTrain,]
# Use createDataPartition to separate training set and test set.
trainclean <- trainclean[,c(-1,-58)]
inTrain <- createDataPartition(y=trainclean$classe,p=0.6, list=FALSE) # split the data set in to 75% training
training <- trainclean[inTrain,]
testing <- trainclean[-inTrain,]
View(testing)
set.seed= 123
rf_model <- caret:: train (classe~.,
data=training,
method="ranger",
trControl=ctrl,
metric="Accuracy",
num.trees=500,
tuneGrid= tgrid)
set.seed= 123
tgrid <- expand.grid(mtry=1:15, splitrule="gini", min.node.size=c(1, 10))
ctrl <- trainControl(method="cv", number=10)
rf_model <- caret:: train (classe~.,
data=training,
method="ranger",
trControl=ctrl,
metric="Accuracy",
num.trees=500,
tuneGrid= tgrid)
print(rf_model)
predrf <- predict(rf_model,testing)
confusionMatrix(testing$classe,predrf)$table
class(training$classe)
trainclean$classe <- as.factor(trainclean$classe )
training <- trainclean[inTrain,]
testing <- trainclean[-inTrain,]
class(training$classe)
set.seed= 123
tgrid <- expand.grid(mtry=3:15, splitrule="gini", min.node.size=c(1, 10))
ctrl <- trainControl(method="cv", number=10)
rf_model <- caret:: train (classe~.,
data=training,
method="ranger",
trControl=ctrl,
metric="Accuracy",
num.trees=500,
tuneGrid= tgrid)
print(rf_model)
set.seed= 123
tgrid <- expand.grid(mtry=6:20, splitrule="gini", min.node.size=c(1, 10))
ctrl <- trainControl(method="cv", number=10)
rf_model <- caret:: train (classe~.,
data=training,
method="ranger",
trControl=ctrl,
metric="Accuracy",
num.trees=500,
tuneGrid= tgrid)
print(rf_model)
confusionMatrix(predrf,testing$classe)$table
confusionMatrix(predrf,testing$classe)
ctrl<- trainControl(method="cv", number=10)
tree_model <- train(classe~.,
data=training,
method="rpart",
trControl=ctrl,
metric="Accuracy",
num.trees=500)
tree_model <- train(classe~.,
data=training,
method="rpart",
trControl=ctrl,
metric="Accuracy")
print(tree_model)
predtree <- predict(tree_model,testing)
confusionMatrix(predtree,testing$classe)
# Predicting Results on the Test Data
rfPredcitions <- predict(rf_model, newdata = testclean)
rfPredcitions
features <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/features.txt", col.names = c("n","functions"))
activities <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/activity_labels.txt", col.names = c("code", "activity"))
subject_test <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/test/subject_test.txt", col.names = "subject")
x_test <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/test/X_test.txt", col.names = features$functions)
y_test <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/test/y_test.txt", col.names = "code")
subject_train <- read.table("UCI HAR Dataset/train/subject_train.txt", col.names = "subject")
X <- rbind(x_train, x_test)
# You should create one R script called run_analysis.R that does the following.
#read the datasets
features <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/features.txt", col.names = c("n","functions"))
activities <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/activity_labels.txt", col.names = c("code", "activity"))
subject_test <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/test/subject_test.txt", col.names = "subject")
x_test <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/test/X_test.txt", col.names = features$functions)
y_test <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/test/y_test.txt", col.names = "code")
subject_train <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/train/subject_train.txt", col.names = "subject")
x_train <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/train/X_train.txt", col.names = features$functions)
y_train <- read.table("~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/UCI HAR Dataset/train/y_train.txt", col.names = "code")
X <- rbind(x_train, x_test)
Y <- rbind(y_train, y_test)
Subject <- rbind(subject_train, subject_test)
Merged_Data <- cbind(Subject, Y, X)
View(Merged_Data)
Rawdata <- cbind(Subject, Y, X)
extracts <- Rawdata %>%
select(subject, code, contains("mean"), contains("std"))
View(Rawdata)
View(Rawdata)
View(Rawdata)
View(Rawdata)
View(activities)
View(extracts)
extracts$code <- activities[extracts$code, 2]
View(extracts)
Appropriately labels the data set with descriptive variable names.
# Appropriately labels the data set with descriptive variable names.
names(extracts)[2] = "activity"
names(extracts)<-gsub("Acc", "Accelerometer", names(extracts))
names(extracts)<-gsub("Gyro", "Gyroscope", names(extracts))
names(extracts)<-gsub("BodyBody", "Body", names(extracts))
names(extracts)<-gsub("Mag", "Magnitude", names(extracts))
names(extracts)<-gsub("^t", "Time", names(extracts))
names(extracts)<-gsub("^f", "Frequency", names(extracts))
names(extracts)<-gsub("tBody", "TimeBody", names(extracts))
names(extracts)<-gsub("-mean()", "Mean", names(extracts), ignore.case = TRUE)
names(extracts)<-gsub("-std()", "STD", names(extracts), ignore.case = TRUE)
names(extracts)<-gsub("-freq()", "Frequency", names(extracts), ignore.case = TRUE)
names(extracts)<-gsub("angle", "Angle", names(extracts))
names(extracts)<-gsub("gravity", "Gravity", names(extracts))
secdata <- extracts %>%
group_by(subject, activity) %>%
summarise_all(funs(mean))
# From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
library(doBy)
# From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
install.packages("doBy")
library(doBy)
# From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
install.packages("collapse")
library(collapse)
secdata <- collap(extracts, .~subject+activity, FUN=mean)
x <- names(extracts)
x <- names(extracts)[-c(1,2)]
secdata <- collap(extracts, x~subject+activity, FUN=mean)
secdata <- collap(extracts, extracts$x~subject+activity, FUN=mean)
secdata <- extracts %>%
group_by(subject, activity) %>%
summarise_all(mean)
View(secdata)
write.table(FinalData, "~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/secdata.txt", row.name=FALSE)
View(secdata)
write.table(secdata, "~/Documents/GitHub/Coursera_Data_Science_Certificate/3_Data_cleaning/secdata.txt", row.name=FALSE)
install.packages("codebook")
library(codebook)
new_codebook_rmd()
