data<- data.frame(Column1 = c('P1', 'P1', 'P2', 'P3', 'P1', 'P1', 'P3', 'P4', 'P2', 'P4'), Column2 = c(5, 5, 3, 5, 2, 3, 4, 7, 10, 14))
View(data)
distinct(data,Column1)
library(dplyr)
distinct(data,Column1)
dat<-distinct(data,Column1)
View(dat)
data<- data.frame(Column1 = c('P1', NA, 'P2', 'P3', 'P1', 'P1', 'P3', 'P4', 'P2', 'P4'), Column2 = c(5, 5, 3, 5, 2, 3, 4, 7, 10, 14))
dat<-distinct(data,Column1)
View(dat)
data2<-mutate(data,Column1=tolower(Column1))
View(data2)
View(data)
id <- c(1,1,1,1,2,2,3,3,4,4,4)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,30,22,24,11,11,12)
mydata <- data.frame(id, day, value)
View(mydata)
View(mydata)
mm <-mydata %>%
group_by(id, day) %>%
filter(row_number(value) == 1)
library(dplyr)
mm <-mydata %>%
group_by(id, day) %>%
filter(row_number(value) == 1)
id <- c(1,1,1,1,2,2,3,3,4,4,4)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,30,22,24,11,11,12)
mydata <- data.frame(id, day, value)
mm <-mydata %>%
group_by(id, day) %>%
filter(row_number(value) == 1)
View(mm)
View(mm)
mm1 <-mydata %>%
group_by(id, day) %>%
arrange(value) %>%
filter(row_number(value) == 1)
View(mm1)
View(mm1)
mm1 <-mydata %>%
group_by(id, day) %>%
arrange(value)
id <- c(1,1,1,1,2,2,3,3,4,4,4)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,30,22,24,11,11,12)
mydata <- data.frame(id, day, value)
mm1 <-mydata %>%
group_by(id, day) %>%
arrange(value)
mm1 <-mydata %>%
group_by=c(id, day) %>%
arrange(value)
mm1 <-mydata %>%
group_by(id, day) %>%
arrange(value)
mm1 <-mydata %>%
group_by(id, day) %>%
arrange(value) %>%
filter(row_number(value) == 1)
mm1 <-mydata %>%
group_by(id, day) %>%
arrange(value) %>%
filter(row_number(value) == 1) %>%
ungroup() %>%
arrange(id,day)
id <- c(1,1,1,1,2,2,3,3,4,4,4)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,"111wo",22,24,11,11,12)
mydata <- data.frame(id, day, value)
as.numeric(mydata$value)
id <- c(1,1,1,1,2,2,3,3,4,4,0)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,"111wo",22,24,11,11,12)
mydata <- data.frame(id, day, value)
mydata<-mydata %>%
mutate(id=tolower(gsub(" ","",id)))
str(mydata)
id <- c(1,1,1,1,2,2,3,3,4,4,0)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,"111wo",22,24,11,11,12)
mydata <- data.frame(id, day, value)
str(mydata)
id <- c(1,1,1,1,2,2,3,3,4,4,NA)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,"111wo",22,24,11,11,12)
mydata <- data.frame(id, day, value)
str(mydata)
mydata<-mydata %>%
mutate(id=tolower(gsub(" ","",id)))
str(mydata)
id <- c(1,1,1,1,2,2,3,3,4,4,NA)
day <- c(1,1,2,3,1,2,2,3,1,2,3)
value <- c(12,10,15,20,40,"111wo",22,24,11,11,12)
mydata <- data.frame(id, day, value)
A <- data.frame(id = c(1,1,4,4,4),
obs1 = c(100, 90,80, 80, 100),id2 = c(1,2,4,4,5))
B <- data.frame(id = c(4,4,4,4,4),
obs1 = c(100, 90,80, 80, 100),id2 = c(1,2,4,4,5))
df <- list("F"=A, "E"=B)
group <- function(x){
x <-x %>%
filter(id==4)
}
myy <-lapply(df,group)
list2env(myy,envir=.GlobalEnv)
shiny::runApp('Documents/GitHub/Coursera_Data_Science_Certificate/9_Data Products/MyAPP')
runApp('Documents/GitHub/Coursera_Data_Science_Certificate/9_Data Products/sliderAPP')
runApp('Documents/GitHub/Coursera_Data_Science_Certificate/9_Data Products/PlotAPP')
# Set working directory
setwd("~/Documents/GitHub/Coursera_Data_Science_Certificate/10_Data Science Capstone")
library(corpus) # corpus is an R text processing package with full suppport for international text (Unicode)
library(dplyr)
library(ggplot2)
library(tm) # package used to remove numbers and strip whitespace from a text document
library(stringi) # the function checks whether all bytes in a string are in the ascii set 1,2,3,4...,127
twitter <- readLines("final/en_US/en_US.twitter.txt", 5000, encoding="UTF-8", skipNul=TRUE)
vs <- VectorSource(twitter)
inspect(VCorpus(vs))
x <-VCorpus(vs)
y <- data.frame(text=unlist(sapply(x,`[`, "content")),stringsAsFactors = FALSE)
View(y)
gram <- NGramTokenizer(y, Weka_control(min=1,max=1))
library(RWeka)
install.packages("RWeka")
gram <- NGramTokenizer(y, Weka_control(min=1,max=1))
install.packages("NLP")
install.packages("NLP")
gram <- NGramTokenizer(y, Weka_control(min=1,max=1))
install.packages("SnowballC")
gram <- NGramTokenizer(y, Weka_control(min=1,max=1))
install.packages("RWeka")
suppressMessages(library(NLP))
library(tm)
library(SnowballC)
library(stringi)
library(RWeka)
gram <- NGramTokenizer(y, Weka_control(min=1,max=1))
install.packages("textmineR")
library(textmineR)
gram <- NGramTokenizer(y, Weka_control(min=1,max=1))
?NGramTokenizer
?NGramTokenizer
??NGramTokenizer
install.packages("Weka_tokeniers")
library(Weka_tokenizers)
library(RWeka)
$ sudo R CMD javareconf
install.packages("rJava",type = "source")
install.packages("RWeka")
gram <- NGramTokenizer(y, Weka_control(min=1,max=1))
library(RWeka)
library(rJava)
library(rJava)
gram <- NGramTokenizer(y, Weka_control(min=1,max=1))
library(RWeka)
load("/Users/wei/Desktop/dataScienceCaptoneProject-gh-pages/unigram.RData")
load("/Users/wei/Desktop/dataScienceCaptoneProject-gh-pages/trigram.RData")
load("/Users/wei/Desktop/dataScienceCaptoneProject-gh-pages/unigram.RData")
load("/Users/wei/Desktop/dataScienceCaptoneProject-gh-pages/unigram.RData")
load("/Users/wei/Desktop/dataScienceCaptoneProject-gh-pages/guessing_next_word/bigram.RData")
load("/Users/wei/Desktop/dataScienceCaptoneProject-gh-pages/guessing_next_word/bigram.RData")
load("/Users/wei/Desktop/dataScienceCaptoneProject-gh-pages/guessing_next_word/RDATA/bigram.RData")
load("~/Desktop/dataScienceCaptoneProject-gh-pages/unigram.RData")
readRDS("~/Desktop/dataScienceCaptoneProject-gh-pages/unigram.RData")
xx <- readRDS("~/Desktop/dataScienceCaptoneProject-gh-pages/unigram.RData")
View(x)
readRDS("~/Desktop/dataScienceCaptoneProject-gh-pages/bigram.RData"
)
twitter <- readLines("final/en_US/en_US.twitter.txt", encoding="UTF-8", skipNul=TRUE)
blogs <- readLines("final/en_US/en_US.blogs.txt", encoding="UTF-8", skipNul=TRUE)
news <- readLines("final/en_US/en_US.news.txt", encoding="UTF-8", skipNul=TRUE)
data_combine <- c(twitter, blogs, news)
library(dplyr)
data_combine <- c(twitter, blogs, news) %>%
slice_sample(n=8000, replace= FALSE)
data_combine <- data.frame(c(twitter, blogs, news)) %>%
slice_sample(n=8000, replace= FALSE)
View(data_combine)
data_sample <- sample(data_combine, size=8000, replace=FALSE)
data_combine <- c(twitter, blogs, news)
data_sample <- sample(data_combine, size=8000, replace=FALSE)
1+1
